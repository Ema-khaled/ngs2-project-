Hello everybody, the following is the scripts or steps for variant calling:

## create and activate the conda env if you did not have it:
$ conda create -y --name ngs1 python=3.6
$ conda activate ngs1
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#1-Download the reference file (human genome) from https://www.ncbi.nlm.nih.gov/genome/guide/human/ and ubload it in the following directory:
$ mkdir -p ~/workdir/sample_data && cd ~/workdir/sample_data
$ gunzip GRCh38_latest_genomic.fna.gz
## By Looking at the downloaded fasta file, we can see it is completed and it is about 4 GB!!:
$ ls -tral GRCh38_latest_genomic.fna
-rw-rw-r-- 1 ngs ngs 3313061631 Feb 25 23:53 GRCh38_latest_genomic.fna
## I noticed that it is downloaded in the fna formate and to be sure that it is a fasta formate, I will use the SeqKit
##SeqKit: is the cross-platform and ultrafast toolkit for FASTA/Q file manipulation
## for more information about SeqKit, please visit: https://bioinf.shenwei.me/seqkit/usage/
$ conda install -c bioconda seqkit
$ cd ..

## now we could explore our reference human genome using the following commands:
$ seqkit stat sample_data/GRCh38_latest_genomic.fna
file                                   format  type  num_seqs        sum_len  min_len      avg_len      max_len
sample_data/GRCh38_latest_genomic.fna  FASTA   DNA        639  3,272,089,205      970  5,120,640.4  248,956,422

#to explore the sequence
$ seqkit seq sample_data/GRCh38_latest_genomic.fna | head -6
>NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#2-Download the sample_data Fastq files (the secound data in our bioproject) (the accession:SRX5059368,the run: SRR8241113, ILLUMINA (Illumina HiSeq 2000) run: 29.5M spots, 5.3G bases, 2.7Gb downloads):
$ mkdir -p ~/workdir/fqData && cd ~/workdir/fqData

##To download the run by accession using prefetch (The actual file will be downloaded to the cache area in my filesystem):
$ conda install -c bioconda sra-tools
$ prefetch SRR8241113

## To Know the path of the downloaded runs:
$ srapath SRR8241113
/home/ngs/workdir/fqData/SRR8241113/SRR8241113.sra

##The run file is compressed, occupying on disk about 2911751441 (about 3 GB):
$ ls -tral /home/ngs/workdir/fqData/SRR8241113/SRR8241113.sra
-rw-rw-r-- 1 ngs ngs 2911751441 Feb 25 23:20 /home/ngs/workdir/fqData/SRR8241113/SRR8241113.sra

##Produces two fastq files (--split-files) containing ".1" and ".2" read suffices (-I) for paired-end data: 
$ fastq-dump --split-files SRR8241113
$ ls -tral (The two reads files occupying on disk about 8807663814 for each read (about 9 GB each):
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01  SRR8241113_2.fastq
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01  SRR8241113_1.fastq
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#3-visualizes the quality of the data using FASTQC
##Note: FASTQC does not perform quality control: it only visualizes the quality of the data.
##Create conda env
## create the conda env if you have not already did
$ conda create -y --name ngs1 python=3.6
##Install the software
$ conda activate ngs1
$ conda install -c bioconda fastqc 
$ conda install -c bioconda multiqc 

##Explore the help of FASTQC
mkdir -p ~/workdir/FASTQC_tut && cd ~/workdir/FASTQC_tut
fastqc -h > fastqc_hlp
less fastqc_hlp

##Run the FASTQC for each read end
$ for f in ~/workdir/fqData/*.fastq;do fastqc -f fastq $f;done
$ ls -tral
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01 SRR8241113_2.fastq
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01 SRR8241113_1.fastq
-rw-rw-r-- 1 ngs ngs 260091 Feb 26 12:35 SRR8241113_1_fastqc.zip
-rw-rw-r-- 1 ngs ngs 233962 Feb 26 12:35 SRR8241113_1_fastqc.html
-rw-rw-r-- 1 ngs ngs 261625 Feb 26 12:38 SRR8241113_2_fastqc.zip
-rw-rw-r-- 1 ngs ngs 235198 Feb 26 12:38 SRR8241113_2_fastqc.html

So I found that the storage spaces are : 260091 and 261625 for SRR8241113_1_fastqc.zip and SRR8241113_2_fastqc.zip respectively.
##Trust HTML to load and explore them: all data were of high quality.

## Now I will Merge the output reports into one super report
$ cd ..
$ cd FASTQC_tut/
$ mv ../fqData/*html ./
$ mv ../fqData/*zip ./
## Using multiqc for merging the two html files 
$ multiqc -h > multiqc_help
(Note from multiqc_help page: -z compress and it will be here in the current directory, -o the output will be here in the current directory, the last . is the working directory)
-z, --zip-data-dir              Compress the data directory.
-o, --outdir TEXT               Create report in the specified output
                                  directory.

$ multiqc -z -o . .
$ ls -tral
-rw-rw-r-- 1 ngs ngs 1151987 Feb 26 14:12  multiqc_report.html
-rw-rw-r-- 1 ngs ngs   13073 Feb 26 14:12  multiqc_data.zip

## View the results

   # Open jupyter
   # Browse to ~/workdir/FASTQC_tut
   # Double click on the file multiqc_report.html:
   file:///home/shimaa/Downloads/multiqc_report.html
      # On the top left of the multiqc_report.html tab header, click on Trust HTML
   # Trust HTML to load and explore them
   ##all data were of high quality.
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#3-Trimmomatic application to Cut the adapter and other illumina-specific sequences from the data reads according to their quality scores
##Trimmomatric is an easy application and have an access to the illumina reads. Trimmomatric will align the technical sequences (all artificial sequences used by ilumina during library preparation) on my reads sequence; if they aligned (means chimeric reaction), Trimmomatric will remove these reads
##Install the software
$ conda activate ngs1
$ conda install -c bioconda trimmomatic 
##Run Trimmomatic
## 1. Create practicing directory
mkdir -p ~/workdir/trimmed && cd ~/workdir/trimmed 
## 2. Set environmental variables
$
f1="$HOME/workdir/fqData/SRR8241113_1.fastq"
f2="$HOME/workdir/fqData/SRR8241113_2.fastq"
newf1="$HOME/workdir/fqData/SRR8241113_1.pe.trim.fastq"
newf2="$HOME/workdir/fqData/SRR8241113_2.pe.trim.fastq"
newf1U="$HOME/workdir/fqData/SRR8241113_1.se.trim.fastq"
newf2U="$HOME/workdir/fqData/SRR8241113_1.se.trim.fastq"
adap="$CONDA_PREFIX/share/trimmomatic-0.39-1/adapters"


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

##Sequence Alignment








