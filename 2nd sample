Hello everybody, the following is the scripts or steps for variant calling:

                               ## create and activate the conda env if you did not have it:
$ conda create -y --name ngs1 python=3.6
$ conda activate ngs1

                                                ##Sequence Alignment
#1-Download the reference file (human genome) from https://www.ncbi.nlm.nih.gov/genome/guide/human/ and ubload it in the following directory:
$ mkdir -p ~/workdir/sample_data && cd ~/workdir/sample_data
$ gunzip GRCh38_latest_genomic.fna.gz
## By Looking at the downloaded fasta file, we can see it is completed and it is about 4 GB!!:
$ ls -tral GRCh38_latest_genomic.fna
-rw-rw-r-- 1 ngs ngs 3313061631 Feb 25 23:53 GRCh38_latest_genomic.fna
## I noticed that it is downloaded in the fna formate and to be sure that it is a fasta formate, I will use the SeqKit
##SeqKit: is the cross-platform and ultrafast toolkit for FASTA/Q file manipulation
## for more information about SeqKit, please visit: https://bioinf.shenwei.me/seqkit/usage/

$ conda install -c bioconda seqkit
## now we could explore our reference human genome:
$ cd ..

$ seqkit stat sample_data/*
file                                   format  type  num_seqs        sum_len  min_len      avg_len      max_len
sample_data/GRCh38_latest_genomic.fna  FASTA   DNA        639  3,272,089,205      970  5,120,640.4  248,956,422

## GC content: seqkit fx2tab coverts FASTA/Q to 3-column tabular format (1st: name/ID, 2nd: sequence, 3rd: quality), and can also provide various information in new columns, including sequence length, GC content/GC skew, alphabet
seqkit fx2tab --name --only-id --gc sample_data/hairpin.fa.gz








#2-Download the sample_data Fastq files (the secound data in our bioproject) (the accession:SRX5059368,the run: SRR8241113, ILLUMINA (Illumina HiSeq 2000) run: 29.5M spots, 5.3G bases, 2.7Gb downloads):
$ mkdir -p ~/workdir/fqData && cd ~/workdir/fqData

##To download the run by accession using prefetch (The actual file will be downloaded to the cache area in my filesystem):
$ conda install -c bioconda sra-tools
$ prefetch SRR8241113

## To Know the path of the downloaded runs:
$ srapath SRR8241113
/home/ngs/workdir/fqData/SRR8241113/SRR8241113.sra

##The run file is compressed, occupying on disk about 2911751441 (about 3 GB):
$ ls -tral /home/ngs/workdir/fqData/SRR8241113/SRR8241113.sra
-rw-rw-r-- 1 ngs ngs 2911751441 Feb 25 23:20 /home/ngs/workdir/fqData/SRR8241113/SRR8241113.sra

##Produces two fastq files (--split-files) containing ".1" and ".2" read suffices (-I) for paired-end data: 
$ fastq-dump --split-files SRR8241113
$ ls -tral (The two reads files occupying on disk about 8807663814 for each read (about 9 GB each):
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01  SRR8241113_2.fastq
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01  SRR8241113_1.fastq

#3-visualizes the quality of the data using FASTQC
##Note: FASTQC does not perform quality control: it only visualizes the quality of the data.
##Create conda env
## create the conda env if you have not already did
$ conda create -y --name ngs1 python=3.6
##Install the software
$ conda activate ngs1
$ conda install -c bioconda fastqc 
$ conda install -c bioconda multiqc 

##Explore the help of FASTQC
mkdir -p ~/workdir/FASTQC_tut && cd ~/workdir/FASTQC_tut
fastqc -h > fastqc_hlp
less fastqc_hlp

##Run the FASTQC for each read end
$ for f in ~/workdir/fqData/*.fastq;do fastqc -f fastq $f;done
$ ls -tral
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01 SRR8241113_2.fastq
-rw-rw-r-- 1 ngs ngs 8807663814 Feb 26 10:01 SRR8241113_1.fastq
-rw-rw-r-- 1 ngs ngs 260091 Feb 26 12:35 SRR8241113_1_fastqc.zip
-rw-rw-r-- 1 ngs ngs 233962 Feb 26 12:35 SRR8241113_1_fastqc.html
-rw-rw-r-- 1 ngs ngs 261625 Feb 26 12:38 SRR8241113_2_fastqc.zip
-rw-rw-r-- 1 ngs ngs 235198 Feb 26 12:38 SRR8241113_2_fastqc.html

So I found that the storage spaces are : 260091 and 261625 for SRR8241113_1_fastqc.zip and SRR8241113_2_fastqc.zip respectively.
##Trust HTML to load and explore them: all data were of high quality.

## Now I will Merge the output reports into one super report
$ cd ..
$ cd FASTQC_tut/
$ mv ../fqData/*html ./
$ mv ../fqData/*zip ./
## Using multiqc for merging the two html files 
$ multiqc -h > multiqc_help
(Note from multiqc_help page: -z compress and it will be here in the current directory, -o the output will be here in the current directory, the last . is the working directory)
-z, --zip-data-dir              Compress the data directory.
-o, --outdir TEXT               Create report in the specified output
                                  directory.

$ multiqc -z -o . .
$ ls -tral
-rw-rw-r-- 1 ngs ngs 1151987 Feb 26 14:12  multiqc_report.html
-rw-rw-r-- 1 ngs ngs   13073 Feb 26 14:12  multiqc_data.zip

## View the results

   # Open jupyter
   # Browse to ~/workdir/FASTQC_tut
   # Double click on the file multiqc_report.html:
   file:///home/shimaa/Downloads/multiqc_report.html
      # On the top left of the multiqc_report.html tab header, click on Trust HTML
   # Trust HTML to load and explore them
   ##all data were of high quality.














